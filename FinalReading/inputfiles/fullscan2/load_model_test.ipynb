{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131f63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from matplotlib import gridspec\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"3\" #\"1\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f761c230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pT [1.14153016e-01 4.42505935e-02 1.12746287e-02 2.48466471e-03\n",
      " 4.61333135e-04 5.48850507e-05] \n",
      "\n",
      "qT [3.71788664 3.15515276 1.6217853  0.67385528 0.22026417 0.06857809\n",
      " 0.00556623] \n",
      "\n",
      "dphi [6.0440479  3.61537102 2.04092379 1.01350616 0.42071553 0.15811563\n",
      " 0.06210802] \n",
      "\n",
      "eta [0.30323704 0.58048175 0.34988284 0.13340729 0.0615625 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for obs in ['pT','qT','dphi','eta']:\n",
    "\n",
    "\n",
    "    nominal_R = [np.load(\"storage_files/Rapgap_nominaln_Omni_step2_\"+obs+\"_iteration4.npy\")]\n",
    "    #nominal_D += [np.load(\"storage_files/Django_nominaln_Omni_step2_\"+obs+\"_iteration4.npy\")]\n",
    "    print(obs,nominal_R[0], \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd10fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = {}\n",
    "\n",
    "#jet pt\n",
    "bins[0] = np.logspace(np.log10(10),np.log10(100),7)\n",
    "\n",
    "#jet eta\n",
    "bins[1] = np.linspace(-1,2.5,6)\n",
    "\n",
    "#dphi\n",
    "bins[2] = np.logspace(np.log10(0.03),np.log10(np.pi/2.0),9) - 0.03\n",
    "bins[2] = bins[2][1:]\n",
    "bins[2][0] = 0.0\n",
    "\n",
    "#qt\n",
    "bins[3] = np.logspace(np.log10(0.03),np.log10(3.03),9) - 0.03\n",
    "bins[3] = bins[3][1:]\n",
    "bins[3][0] = 0.0\n",
    "\n",
    "#Read in the data\n",
    "data = pd.read_pickle(\"datafiles/data.pkl\")\n",
    "theta_unknown_S = data[['e_px','e_py','e_pz','jet_pt','jet_eta','jet_phi','jet_dphi','jet_qtnorm']].to_numpy()\n",
    "\n",
    "\n",
    "scaler_data = StandardScaler()\n",
    "scaler_data.fit(theta_unknown_S)\n",
    "\n",
    "#Read in the MC\n",
    "mc = pd.read_pickle(\"/clusterfs/ml4hep/bpnachman/H1/july16/datasets/Rapgap_nominal.pkl\")\n",
    "theta0_S = mc[['e_px','e_py','e_pz','jet_pt','jet_eta','jet_phi','jet_dphi','jet_qtnorm']].to_numpy()\n",
    "theta0_G = mc[['gene_px','gene_py','gene_pz','genjet_pt','genjet_eta','genjet_phi','genjet_dphi','genjet_qtnorm']].to_numpy()\n",
    "weights_MC_sim = mc['wgt']\n",
    "pass_reco = np.array(mc['pass_reco'])\n",
    "pass_truth = np.array(mc['pass_truth'])\n",
    "pass_fiducial = np.array(mc['pass_fiducial'])\n",
    "\n",
    "del mc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7157abf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicated result with saved model [3.71788664 3.15515276 1.6217853  0.67385528 0.22026417 0.06857809\n",
      " 0.00556623]\n",
      "Result from training session [3.71788664 3.15515276 1.6217853  0.67385528 0.22026417 0.06857809\n",
      " 0.00556623]\n",
      "Difference:  [0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "NNweights_step2 = np.ones(len(theta0_S))\n",
    "for i in range(5):\n",
    "    mymodel = tf.keras.models.load_model(\"models/Rapgap_nominal_iteration\"+str(i)+\"_step2\", compile=False)\n",
    "    NNweights_step2_hold = mymodel.predict(scaler_data.transform(theta0_G),batch_size=10000)\n",
    "    NNweights_step2_hold = NNweights_step2_hold/(1.-NNweights_step2_hold)\n",
    "    NNweights_step2_hold = NNweights_step2_hold[:,0]\n",
    "    NNweights_step2_hold = np.squeeze(np.nan_to_num(NNweights_step2_hold,posinf=1))\n",
    "    NNweights_step2_hold[pass_truth==0] = 1.\n",
    "    NNweights_step2 = NNweights_step2_hold*NNweights_step2\n",
    "\n",
    "#trying to replicate result for qT\n",
    "\n",
    "n_Omni_step2_qT,_,_=plt.hist(theta0_G[pass_fiducial==1][:,7],\n",
    "                             bins=bins[3],weights=weights_MC_sim[pass_fiducial==1]*NNweights_step2[pass_fiducial==1],\n",
    "                             density=True,histtype=\"step\",color=\"black\",ls=\":\",label=\"MC + step 2\")\n",
    "\n",
    "print(\"Replicated result with saved model\", n_Omni_step2_qT) #could be the saved model is not just fro step 2...\n",
    "print(\"Result from training session\", np.load(\"storage_files/Rapgap_nominaln_Omni_step2_qT_iteration4.npy\"))\n",
    "print(\"Difference: \", n_Omni_step2_qT - np.load(\"storage_files/Rapgap_nominaln_Omni_step2_qT_iteration4.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2e651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
